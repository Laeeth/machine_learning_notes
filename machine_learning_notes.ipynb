{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OS/ User specific \n",
    "\n",
    "TRAINING_DATASET_PATH = \"/home/jcharlet/workspace/datascience/machine_learning_notes/data\" + '/train.csv'\n",
    "# TRAINING_DATASET_PATH = os.path.abspath(os.path.join( os.getcwd() , 'data')) + r'\\train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle project - Table of Contents\n",
    "* 1 - Define the problem\n",
    "* [Load data and displaying info](#load-data)\n",
    "* 2 - Prepare Data\n",
    "    * Identify features\n",
    "        * Separate numerical from categorical features\n",
    "        * Separate nominal and ordinal (from categorical features)\n",
    "    * Clean data\n",
    "        * Remove numerical features with missing values\n",
    "        * Remove categorical features with missing values\n",
    "        * drop outliers in numerical values # WIP\n",
    "    * transform # TODO\n",
    "        * transform categorical values #TODO\n",
    "* 2 - Feature selection #WIP\n",
    "    * Select features using random forest classifier #WIP\n",
    "    \n",
    "* 3 - Spot Check Algorithms\n",
    "    * split dataset\n",
    "    * train on multiple algorithms  # WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From project https://www.kaggle.com/c/house-prices-advanced-regression-techniques\n",
    "\n",
    "- Step 1: What is the problem? \n",
    "\n",
    "house prices are hard to predict, we want to know how much my beautiful flat is worth on the market in the USA\n",
    "\n",
    "- Step 2: Why does the problem need to be solved? \n",
    "\n",
    "MONEY MONEY\n",
    "and especially we need to learn Machine Learning\n",
    "\n",
    "- Step 3: How would I solve the problem? \n",
    "\n",
    "housing agents do statistical studies.\n",
    "\n",
    "Data pre-processing is very important. We have a lot of features, dirty data (missing values), numerical/ordinal/nominal values.\n",
    "\n",
    "We'll follow the process from https://machinelearningmastery.com/process-for-working-through-machine-learning-problems/\n",
    "\n",
    "- 1 - Define the Problem\n",
    "- 2 - Prepare Data\n",
    "- 3 - Spot Check Algorithms\n",
    "- 4 - Improve Results\n",
    "- 5 - Present Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data <a class=\"anchor\" id=\"load-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAINING_DATASET_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data <a class=\"anchor\" id=\"clean-data\"></a>\n",
    "## Identify features\n",
    "### Separate numerical from categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separating data features according to data type: numeric or string\n",
    "\n",
    "X_numeric_labels = set(df._get_numeric_data().columns.tolist())\n",
    "X_categorical_labels = set(df.columns.tolist()).difference(X_numeric_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are numerical features {'WoodDeckSF', 'GarageCars', '3SsnPorch', 'Fireplaces', 'FullBath', 'SalePrice', 'Id', 'LowQualFinSF', 'HalfBath', '2ndFlrSF', 'GarageArea', 'YearBuilt', 'MSSubClass', 'GarageYrBlt', 'ScreenPorch', 'BsmtFinSF1', 'LotArea', 'OverallCond', '1stFlrSF', 'BedroomAbvGr', 'TotRmsAbvGrd', 'BsmtHalfBath', 'PoolArea', 'MoSold', 'YearRemodAdd', 'OverallQual', 'TotalBsmtSF', 'KitchenAbvGr', 'GrLivArea', 'MasVnrArea', 'BsmtUnfSF', 'OpenPorchSF', 'YrSold', 'BsmtFinSF2', 'EnclosedPorch', 'BsmtFullBath', 'LotFrontage', 'MiscVal'} \n",
      "\n",
      "These are categorical features {'CentralAir', 'KitchenQual', 'BsmtFinType2', 'HouseStyle', 'BsmtExposure', 'LandContour', 'Functional', 'LandSlope', 'Exterior1st', 'Alley', 'Condition2', 'Electrical', 'MasVnrType', 'Utilities', 'MSZoning', 'GarageType', 'BsmtCond', 'PoolQC', 'GarageCond', 'LotShape', 'SaleCondition', 'PavedDrive', 'Foundation', 'Street', 'BldgType', 'Heating', 'SaleType', 'ExterCond', 'FireplaceQu', 'Fence', 'MiscFeature', 'Neighborhood', 'HeatingQC', 'LotConfig', 'GarageFinish', 'BsmtQual', 'Condition1', 'Exterior2nd', 'RoofMatl', 'GarageQual', 'BsmtFinType1', 'ExterQual', 'RoofStyle'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('These are numerical features {} \\n'.format(X_numeric_labels))\n",
    "print('These are categorical features {} \\n'.format(X_categorical_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate nominal and ordinal (from categorical features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separating categorical features in two sets: nominal and ordinal\n",
    "# The values in features asociated with categorical ordinal feautures are: [Ex, Gd, GLQ, GdPrv, Fin] ... etc\n",
    "\n",
    "categorical_ordinal_list_values = ['Ex', 'Gd', 'GLQ', 'GdPrv', 'Fin'] # There are not iall of the values. Here must be\n",
    "# included all the possible values for the categorical ordinal features\n",
    "\n",
    "X_categorical_nominal_labels = (df[list(X_categorical_labels)].drop(['GarageCond', 'BsmtFinType1', 'BsmtQual','MiscFeature','Alley','GarageType','BsmtFinType2',\n",
    "         'BsmtExposure', 'FireplaceQu', 'MasVnrType', 'GarageQual', 'GarageFinish', 'Fence', 'PoolQC'],\n",
    "        1).isin(categorical_ordinal_list_values) == False).all().loc[lambda df: df.values == True].axes\n",
    "\n",
    "# The previous instruction returns the index of the categorical_nominal_values. I think we could include the following features:\n",
    "#LandSlope has values: Gtl -> Gentle slopen; Mod -> Moderate Slope; Sev -> Severe Slope\n",
    "#Functional has values: Typ -> Typical Functionality; Min1 -> Minor Deductions 1; Min2 -> Minor Deductions 2; Mod -> Moderate Deductions; Maj1 -> Major Deductions 1; Maj2 -> Major Deductions 2; Sev -> Severely Damaged; Sal -> Salvage only\n",
    "#PavedDrive has values:   Y -> Paved ; P -> Partial Pavement; N -> Dirt/Gravel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Index(['CentralAir', 'HouseStyle', 'LandContour', 'Functional', 'LandSlope',\n",
      "       'Exterior1st', 'Condition2', 'Electrical', 'Utilities', 'MSZoning',\n",
      "       'LotShape', 'SaleCondition', 'PavedDrive', 'Foundation', 'Street',\n",
      "       'BldgType', 'Heating', 'SaleType', 'Neighborhood', 'LotConfig',\n",
      "       'Condition1', 'Exterior2nd', 'RoofMatl', 'RoofStyle'],\n",
      "      dtype='object')]\n",
      "\n",
      "['CentralAir', 'HouseStyle', 'LandContour', 'Functional', 'LandSlope', 'Exterior1st', 'Condition2', 'Electrical', 'Utilities', 'MSZoning', 'LotShape', 'SaleCondition', 'PavedDrive', 'Foundation', 'Street', 'BldgType', 'Heating', 'SaleType', 'Neighborhood', 'LotConfig', 'Condition1', 'Exterior2nd', 'RoofMatl', 'RoofStyle']\n"
     ]
    }
   ],
   "source": [
    "print(X_categorical_nominal_labels)\n",
    "print()\n",
    "print(X_categorical_nominal_labels[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "<p> From the set of set of **X_categorical_labels** the set of **X_categorical_nominal_labels** is extracted to get \n",
    "the set of **X_categorical_ordinal_labels**</p>\n",
    "\n",
    "* On the set of **X_categorical_ordinal_labels** we can apply pag 104 **mapping strategy**\n",
    "\n",
    "* On the set of **X_categorical_nominal_labels** we can apply **one-hot encoding strategy** pag 106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_categorical_ordinal_labels = set(X_categorical_labels).difference(set(X_categorical_nominal_labels[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(X_categorical_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df[list(X_categorical_ordinal_labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Clean data\n",
    "### Remove numerical features with missing values\n",
    "\n",
    "#### Some considerations\n",
    "\n",
    "\n",
    "* <p> Page 107 of \"our book\":  \"After executing the preceding code, the first column of the NumPy array X now holds the new\n",
    "colour values, which are encoded as follows:\n",
    "blue to 0\n",
    "green to 1\n",
    "red to 2\n",
    "If we stop at this point and feed the array to our classifier, *we will make one of the most common \n",
    "mistakes in dealing with categorical data*. Can you spot the problem? *\n",
    "Although the colour values do not come in any particular order, a learning algorithm will now assume\n",
    "that green is larger than blue, and red is larger than green. \n",
    "Although this assumption is incorrect, the algorithm could still produce useful results. \n",
    "However, those results would not be optimal* \"</p>\n",
    "\n",
    "* <p> In the numerical feature variables there is the possibility that there are categorical numerical features variables. How to identify this kinf of features ? \n",
    " I think the main problem is what strategy to use to replace values ? median, mode or mean ? </p>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cleaned=df.copy()\n",
    "\n",
    "\n",
    "#Let's check how many numerical features have missing values\n",
    "\n",
    "# print(df[df._get_numeric_data().columns.tolist()].isnull().sum())\n",
    "\n",
    "# Dropping columns: ['Id', 'LotFrontage', 'GarageYrBlt', 'SalePrice',] from numerical features\n",
    "\n",
    "# dropping Id and \n",
    "df_cleaned= df_cleaned._get_numeric_data().drop(['Id'],1)\n",
    "X_numerical_not_missing_values_labels=df_cleaned[df_cleaned._get_numeric_data().columns.tolist()].isnull().sum().loc[lambda df: df.values == 0].axes[0].tolist()\n",
    "df_cleaned=df[X_numerical_not_missing_values_labels]\n",
    "# df_cleaned = df_cleaned._get_numeric_data().drop(['LotFrontage', 'GarageYrBlt', 'MasVnrArea'],1)\n",
    "\n",
    "# print(df_cleaned[df_cleaned._get_numeric_data().columns.tolist()].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove categorical features with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking for missing values in categorical values in the data set\n",
    "\n",
    "# print(df[list(X_categorical_labels)].isnull().sum())\n",
    "\n",
    "# Dropping categorical features with missing values\n",
    "# The following instruction returns the list of features with no missing values\n",
    "\n",
    "X_categorical_not_missing_values_labels = df[list(X_categorical_labels)].isnull().sum().loc[lambda df: df.values == 0].axes[0].tolist()\n",
    "df_cleaned=df[X_categorical_not_missing_values_labels]\n",
    "# df[list(X_categorical_labels)].drop(X_categorical_not_missing_values_labels, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop outliers in numerical values # WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def drop_outliers(df, field_name):\n",
    "    distance = 1.5 * (np.percentile(df[field_name], 75) - np.percentile(df[field_name], 25))\n",
    "    df.drop(df[df[field_name] > distance + np.percentile(df[field_name], 75)].index, inplace=True)\n",
    "    df.drop(df[df[field_name] < np.percentile(df[field_name], 25) - distance].index, inplace=True)\n",
    "\n",
    "# drop_outliers(df_cleaned, 'LotArea')    \n",
    "df_cleaned_no_outlier = df.copy()\n",
    "for feature in X_numerical_not_missing_values_labels:\n",
    "    drop_outliers(df_cleaned_no_outlier, feature)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb of rows with outliers:1460, without: 584\n"
     ]
    }
   ],
   "source": [
    "print(\"nb of rows with outliers:{}, without: {}\".format(df.shape[0],df_cleaned_no_outlier.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are currently removing far too many items, to review later.\n",
    "can be done with sklearn anyway http://scikit-learn.org/stable/modules/outlier_detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature_columns=filter(lambda x: x !=\"SalePrice\" and x!=\"Id\", df.columns)\n",
    "# feature_numerical_columns = df[feature_columns].select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_numerical_columns=X_numerical_not_missing_values_labels\n",
    "prediction_column=\"SalePrice\"\n",
    "# # print(feature_columns)\n",
    "X = df[feature_numerical_columns]\n",
    "Y=df[[prediction_column]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label MSSubClass : 0.11583775394852835\n",
      "label LotArea : 0.059596391198568036\n",
      "label OverallQual : 0.05929042687921961\n",
      "label OverallCond : 0.05535591335180703\n",
      "label YearBuilt : 0.05339928648765881\n",
      "label YearRemodAdd : 0.05265642588156977\n",
      "label BsmtFinSF1 : 0.051037160212856605\n",
      "label BsmtFinSF2 : 0.049344319785879595\n",
      "label BsmtUnfSF : 0.04507117617143287\n",
      "label TotalBsmtSF : 0.04410527899239075\n",
      "label 1stFlrSF : 0.04333008998472061\n",
      "label 2ndFlrSF : 0.04082381491749085\n",
      "label LowQualFinSF : 0.035963727230624756\n",
      "label GrLivArea : 0.03170844144728096\n",
      "label BsmtFullBath : 0.02767985328649026\n",
      "label BsmtHalfBath : 0.02637204359092779\n",
      "label FullBath : 0.02510182064705983\n",
      "label HalfBath : 0.02093876563531272\n",
      "label BedroomAbvGr : 0.020709375681647144\n",
      "label KitchenAbvGr : 0.02040290304830243\n",
      "label TotRmsAbvGrd : 0.016554703079649347\n",
      "label Fireplaces : 0.01585286962539515\n",
      "label GarageCars : 0.014978839352761194\n",
      "label GarageArea : 0.012217462272628137\n",
      "label WoodDeckSF : 0.01217825478545741\n",
      "label OpenPorchSF : 0.009908416147520072\n",
      "label EnclosedPorch : 0.009198651885259763\n",
      "label 3SsnPorch : 0.008095155241268151\n",
      "label ScreenPorch : 0.006968395653165453\n",
      "label PoolArea : 0.005562833658471988\n",
      "label MiscVal : 0.0037987042235808613\n",
      "label MoSold : 0.002564271074219646\n",
      "label YrSold : 0.002059393222739711\n",
      "label SalePrice : 0.0013370813981143281\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier();\n",
    "model = model.fit(X, Y)    \n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"label {} : {}\".format(feature_numerical_columns[f],importances[indices[f]]))\n",
    "# print(indices)\n",
    "\n",
    "# plt.bar(range(X.shape[1]),importances[indices],align='center')\n",
    "# plt.xticks(range(X.shape[1]),feature_numerical_columns,rotation=90);\n",
    "# plt.rcParams[\"figure.figsize\"] = (17,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To draw graph and select features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot Check Algorithms\n",
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SalePrice\n",
      "615      137500\n",
      "613      147000\n",
      "1303     232000\n",
      "486      156000\n",
      "561      170000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>85</td>\n",
       "      <td>8800</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1963</td>\n",
       "      <td>1963</td>\n",
       "      <td>763</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>936</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>137500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>20</td>\n",
       "      <td>8402</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>914</td>\n",
       "      <td>1120</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2007</td>\n",
       "      <td>147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>20</td>\n",
       "      <td>8688</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1616</td>\n",
       "      <td>1616</td>\n",
       "      <td>...</td>\n",
       "      <td>208</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>20</td>\n",
       "      <td>10289</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>836</td>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "      <td>1073</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>156000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>20</td>\n",
       "      <td>10010</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1974</td>\n",
       "      <td>1975</td>\n",
       "      <td>1071</td>\n",
       "      <td>123</td>\n",
       "      <td>195</td>\n",
       "      <td>1389</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>170000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "615           85     8800            6            7       1963          1963   \n",
       "613           20     8402            5            5       2007          2007   \n",
       "1303          20     8688            7            5       2005          2005   \n",
       "486           20    10289            5            7       1965          1965   \n",
       "561           20    10010            5            5       1974          1975   \n",
       "\n",
       "      BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF    ...      WoodDeckSF  \\\n",
       "615          763           0        173          936    ...             120   \n",
       "613          206           0        914         1120    ...               0   \n",
       "1303           0           0       1616         1616    ...             208   \n",
       "486          836           0        237         1073    ...               0   \n",
       "561         1071         123        195         1389    ...             240   \n",
       "\n",
       "      OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
       "615             0              0          0            0         0        0   \n",
       "613            30              0          0            0         0        0   \n",
       "1303           59              0          0            0         0        0   \n",
       "486             0              0          0            0         0        0   \n",
       "561            38              0          0            0         0        0   \n",
       "\n",
       "      MoSold  YrSold  SalePrice  \n",
       "615        5    2010     137500  \n",
       "613       12    2007     147000  \n",
       "1303       4    2006     232000  \n",
       "486        6    2007     156000  \n",
       "561        4    2006     170000  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[X_numerical_not_missing_values_labels]\n",
    "Y=df[[\"SalePrice\"]];\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.33,random_state=42)\n",
    "print(Y_train.head())\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#training\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn import preprocessing\n",
    "\n",
    "models = []\n",
    "models.append((\"SVC\",SVC()))\n",
    "models.append((\"LinearSVC\",LinearSVC()))\n",
    "models.append((\"KNeighbors\",KNeighborsClassifier()))\n",
    "models.append((\"DecisionTree\",DecisionTreeClassifier()))\n",
    "models.append((\"RandomForest\",RandomForestClassifier()))\n",
    "\n",
    "modelsWhichNeedNormalization = []\n",
    "modelsWhichNeedNormalization.append((\"LogisticRegression\",LogisticRegression()))\n",
    "modelsWhichNeedNormalization.append((\"MLPClassifier\",MLPClassifier(solver='lbfgs', random_state=0)))\n",
    "modelsWhichNeedNormalization.append((\"LinearRegression\", LinearRegression()))\n",
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 expected values: [[154500]\n",
      " [325000]\n",
      " [115000]\n",
      " [159000]\n",
      " [315500]]\n",
      "\n",
      "Training on SVC\n",
      "   mean squared log error: 0.1979351767720077\n",
      "\n",
      "   5 predicted values: [140000 140000 140000 140000 140000]\n",
      "Training on LinearSVC\n",
      "   mean squared log error: 1.195296054472813\n",
      "\n",
      "   5 predicted values: [60000 60000 60000 60000 60000]\n",
      "Training on KNeighbors\n",
      "   mean squared log error: 0.0013517972574133067\n",
      "\n",
      "   5 predicted values: [155000 324000 115000 157000 318000]\n",
      "Training on DecisionTree\n",
      "   mean squared log error: 0.006966509708546483\n",
      "\n",
      "   5 predicted values: [154000 335000 115000 159500 319900]\n",
      "Training on RandomForest\n",
      "   mean squared log error: 0.07289343355858952\n",
      "\n",
      "   5 predicted values: [149000 412500 113000 130000 176000]\n"
     ]
    }
   ],
   "source": [
    "print(\"5 expected values: {}\\n\".format(Y_test[0:5].values))\n",
    "for name,model in models:\n",
    "#     Train the model using the training sets\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pre = model.predict(X_test)\n",
    "    print(\"Training on {}\\n   mean squared log error: {}\\n\".format(name,mean_squared_log_error(Y_test, y_pre)))\n",
    "    print(\"   5 predicted values: {}\".format(y_pre[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# for name,model in modelsWhichNeedNormalization:\n",
    "# #     Train the model using the training sets\n",
    "#     X_train_scaled = preprocessing.scale(X_train)\n",
    "#     model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "#     # Make predictions using the testing set\n",
    "#     X_test_scaled = preprocessing.scale(X_test)\n",
    "#     y_pre = model.predict(X_test_scaled)\n",
    "#     print(\"Training on {}: {}\".format(name,mean_squared_log_error(Y_test, y_pre)))\n",
    "\n",
    "# crash on Jeremie's laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env python3_6)",
   "language": "python",
   "name": "py-dku-venv-python3_6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
