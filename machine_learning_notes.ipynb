{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OS/ User specific \n",
    "import os\n",
    "#TRAINING_DATASET_PATH = \"/home/jcharlet/workspace/datascience/machine_learning_notes/data\" + '/train.csv'\n",
    "TRAINING_DATASET_PATH = os.path.abspath(os.path.join( os.getcwd() , 'data')) + r'\\train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle project - Table of Contents\n",
    "* 1 - Define the problem\n",
    "* [Load data and displaying info](#load-data)\n",
    "* 2 - Prepare Data\n",
    "    * Identify features\n",
    "        * Separate numerical from categorical features\n",
    "        * Separate nominal and ordinal (from categorical features)\n",
    "    * Clean data\n",
    "        * Remove numerical features with missing values\n",
    "        * Remove categorical features with missing values\n",
    "        * drop outliers in numerical values # WIP\n",
    "    * transform # TODO\n",
    "        * transform categorical values #TODO\n",
    "* 2 - Feature selection #WIP\n",
    "    * Select features using random forest classifier #WIP\n",
    "    \n",
    "* 3 - Spot Check Algorithms\n",
    "    * split dataset\n",
    "    * train on multiple algorithms  # WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From project https://www.kaggle.com/c/house-prices-advanced-regression-techniques\n",
    "\n",
    "- Step 1: What is the problem? \n",
    "\n",
    "house prices are hard to predict, we want to know how much my beautiful flat is worth on the market in the USA\n",
    "\n",
    "- Step 2: Why does the problem need to be solved? \n",
    "\n",
    "MONEY MONEY\n",
    "and especially we need to learn Machine Learning\n",
    "\n",
    "- Step 3: How would I solve the problem? \n",
    "\n",
    "housing agents do statistical studies.\n",
    "\n",
    "Data pre-processing is very important. We have a lot of features, dirty data (missing values), numerical/ordinal/nominal values.\n",
    "\n",
    "We'll follow the process from https://machinelearningmastery.com/process-for-working-through-machine-learning-problems/\n",
    "\n",
    "- 1 - Define the Problem\n",
    "- 2 - Prepare Data\n",
    "- 3 - Spot Check Algorithms\n",
    "- 4 - Improve Results\n",
    "- 5 - Present Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data <a class=\"anchor\" id=\"load-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAINING_DATASET_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data <a class=\"anchor\" id=\"clean-data\"></a>\n",
    "## Identify features\n",
    "### Separate numerical from categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separating data features according to data type: numeric or string\n",
    "\n",
    "X_numeric_labels = set(df._get_numeric_data().columns.tolist())\n",
    "X_categorical_labels = set(df.columns.tolist()).difference(X_numeric_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are numerical features {'MasVnrArea', '1stFlrSF', 'Id', '2ndFlrSF', 'LotArea', 'FullBath', 'YearRemodAdd', 'BsmtHalfBath', 'GarageCars', 'GarageArea', 'BsmtUnfSF', 'HalfBath', 'SalePrice', 'KitchenAbvGr', 'MSSubClass', 'MoSold', 'BsmtFinSF2', 'YrSold', 'ScreenPorch', 'BsmtFullBath', 'LowQualFinSF', 'WoodDeckSF', 'PoolArea', 'LotFrontage', 'OverallQual', 'MiscVal', 'GarageYrBlt', 'OverallCond', 'Fireplaces', '3SsnPorch', 'YearBuilt', 'TotalBsmtSF', 'TotRmsAbvGrd', 'BsmtFinSF1', 'OpenPorchSF', 'BedroomAbvGr', 'GrLivArea', 'EnclosedPorch'} \n",
      "\n",
      "These are categorical features {'BsmtCond', 'MiscFeature', 'Heating', 'GarageQual', 'LotShape', 'BsmtQual', 'Exterior1st', 'GarageCond', 'BsmtFinType2', 'PavedDrive', 'Condition2', 'Foundation', 'GarageFinish', 'BsmtFinType1', 'SaleCondition', 'Exterior2nd', 'Alley', 'SaleType', 'CentralAir', 'BsmtExposure', 'Neighborhood', 'HouseStyle', 'Electrical', 'BldgType', 'PoolQC', 'Condition1', 'LotConfig', 'LandSlope', 'Functional', 'RoofMatl', 'HeatingQC', 'LandContour', 'MasVnrType', 'Fence', 'RoofStyle', 'KitchenQual', 'Street', 'Utilities', 'FireplaceQu', 'ExterQual', 'ExterCond', 'MSZoning', 'GarageType'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('These are numerical features {} \\n'.format(X_numeric_labels))\n",
    "print('These are categorical features {} \\n'.format(X_categorical_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate nominal and ordinal (from categorical features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we are dropping any categorical feature with at least one null value, we can relax this requirement by changing df > 0 to \n",
    "# df > n with n > 0\n",
    "\n",
    "categorical_missing_values_labels = df[list(X_categorical_labels)].isnull().sum().loc[lambda df: df > 0].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BsmtCond',\n",
       " 'MiscFeature',\n",
       " 'GarageQual',\n",
       " 'BsmtQual',\n",
       " 'GarageCond',\n",
       " 'BsmtFinType2',\n",
       " 'GarageFinish',\n",
       " 'BsmtFinType1',\n",
       " 'Alley',\n",
       " 'BsmtExposure',\n",
       " 'Electrical',\n",
       " 'PoolQC',\n",
       " 'MasVnrType',\n",
       " 'Fence',\n",
       " 'FireplaceQu',\n",
       " 'GarageType']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_missing_values_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of Total Categorical Values = 43 \n",
      " Number of Categorical Missing Values = 16  \n",
      " Difference = 27\n"
     ]
    }
   ],
   "source": [
    "print(\" Number of Total Categorical Values = {} \\n Number of Categorical Missing Values = {}  \\n Difference = {}\".format(len(X_categorical_labels), len(categorical_missing_values_labels), len(X_categorical_labels)- len(categorical_missing_values_labels) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separating categorical features in two sets: nominal and ordinal\n",
    "# The values in features asociated with categorical ordinal feautures are: [Ex, Gd, GLQ, GdPrv, Fin] ... etc\n",
    "\n",
    "categorical_ordinal_list_values = ['Ex', 'Gd', 'GLQ', 'GdPrv', 'Fin'] # There are not all of the values. Here must be\n",
    "# included all the possible values for the categorical ordinal features\n",
    "\n",
    "X_categorical_nominal_labels = (df[list(X_categorical_labels)].drop(categorical_missing_values_labels,\n",
    "        1).isin(categorical_ordinal_list_values) == False).all().loc[lambda df: df.values == True].axes\n",
    "\n",
    "# The previous instruction returns the index of the categorical_nominal_values. I think we could include the following features:\n",
    "#LandSlope has values: Gtl -> Gentle slopen; Mod -> Moderate Slope; Sev -> Severe Slope\n",
    "#Functional has values: Typ -> Typical Functionality; Min1 -> Minor Deductions 1; Min2 -> Minor Deductions 2; Mod -> Moderate Deductions; Maj1 -> Major Deductions 1; Maj2 -> Major Deductions 2; Sev -> Severely Damaged; Sal -> Salvage only\n",
    "#PavedDrive has values:   Y -> Paved ; P -> Partial Pavement; N -> Dirt/Gravel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Index(['Heating', 'LotShape', 'Exterior1st', 'PavedDrive', 'Condition2',\n",
      "       'Foundation', 'SaleCondition', 'Exterior2nd', 'SaleType', 'CentralAir',\n",
      "       'Neighborhood', 'HouseStyle', 'BldgType', 'Condition1', 'LotConfig',\n",
      "       'LandSlope', 'Functional', 'RoofMatl', 'LandContour', 'RoofStyle',\n",
      "       'Street', 'Utilities', 'MSZoning'],\n",
      "      dtype='object')]\n",
      "\n",
      "['Heating', 'LotShape', 'Exterior1st', 'PavedDrive', 'Condition2', 'Foundation', 'SaleCondition', 'Exterior2nd', 'SaleType', 'CentralAir', 'Neighborhood', 'HouseStyle', 'BldgType', 'Condition1', 'LotConfig', 'LandSlope', 'Functional', 'RoofMatl', 'LandContour', 'RoofStyle', 'Street', 'Utilities', 'MSZoning']\n"
     ]
    }
   ],
   "source": [
    "print(X_categorical_nominal_labels)\n",
    "print()\n",
    "print(X_categorical_nominal_labels[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "<p> From the set of set of **X_categorical_labels** the set of **X_categorical_nominal_labels** is extracted to get \n",
    "the set of **X_categorical_ordinal_labels**</p>\n",
    "\n",
    "* On the set of **X_categorical_ordinal_labels** we can apply pag 104 **mapping strategy**\n",
    "\n",
    "* On the set of **X_categorical_nominal_labels** we can apply **one-hot encoding strategy** pag 106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_categorical_ordinal_labels = set(X_categorical_labels).difference(set(X_categorical_nominal_labels[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(X_categorical_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df[list(X_categorical_ordinal_labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Clean data\n",
    "### Remove numerical features with missing values\n",
    "\n",
    "#### Some considerations\n",
    "\n",
    "\n",
    "* <p> Page 107 of \"our book\":  \"After executing the preceding code, the first column of the NumPy array X now holds the new\n",
    "colour values, which are encoded as follows:\n",
    "blue to 0\n",
    "green to 1\n",
    "red to 2\n",
    "If we stop at this point and feed the array to our classifier, *we will make one of the most common \n",
    "mistakes in dealing with categorical data*. Can you spot the problem? *\n",
    "Although the colour values do not come in any particular order, a learning algorithm will now assume\n",
    "that green is larger than blue, and red is larger than green. \n",
    "Although this assumption is incorrect, the algorithm could still produce useful results. \n",
    "However, those results would not be optimal* \"</p>\n",
    "\n",
    "* <p> In the numerical feature variables there is the possibility that there are categorical numerical features variables. How to identify this kinf of features ? \n",
    " I think the main problem is what strategy to use to replace values ? median, mode or mean ? </p>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cleaned=df.copy()\n",
    "\n",
    "\n",
    "#Let's check how many numerical features have missing values\n",
    "\n",
    "# print(df[df._get_numeric_data().columns.tolist()].isnull().sum())\n",
    "\n",
    "# Dropping columns: ['Id', 'LotFrontage', 'GarageYrBlt', 'SalePrice',] from numerical features\n",
    "\n",
    "# dropping Id and \n",
    "df_cleaned= df_cleaned._get_numeric_data().drop(['Id'],1)\n",
    "X_numerical_not_missing_values_labels=df_cleaned[df_cleaned._get_numeric_data().columns.tolist()].isnull().sum().loc[lambda df: df.values == 0].axes[0].tolist()\n",
    "df_cleaned=df[X_numerical_not_missing_values_labels]\n",
    "# df_cleaned = df_cleaned._get_numeric_data().drop(['LotFrontage', 'GarageYrBlt', 'MasVnrArea'],1)\n",
    "\n",
    "# print(df_cleaned[df_cleaned._get_numeric_data().columns.tolist()].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove categorical features with missing values\n",
    "### We need to change df_cleaned here !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values in categorical values in the data set\n",
    "\n",
    "# print(df[list(X_categorical_labels)].isnull().sum())\n",
    "\n",
    "# Dropping categorical features with missing values\n",
    "# The following instruction returns the list of features with no missing values\n",
    "\n",
    "#X_categorical_not_missing_values_labels = df[list(X_categorical_labels)].isnull().sum().loc[lambda df: df.values == 0].axes[0].tolist()\n",
    "\n",
    "df[list(X_categorical_labels)].drop(X_categorical_not_missing_values_labels, 1).columns.tolist()\n",
    "print(len(df[list(X_categorical_labels)].drop(categorical_missing_values_labels, 1).columns.tolist()))\n",
    "df_cleaned=df[X_categorical_not_missing_values_labels]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop outliers in numerical values # WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def drop_outliers(df, field_name):\n",
    "    distance = 1.5 * (np.percentile(df[field_name], 75) - np.percentile(df[field_name], 25))\n",
    "    df.drop(df[df[field_name] > distance + np.percentile(df[field_name], 75)].index, inplace=True)\n",
    "    df.drop(df[df[field_name] < np.percentile(df[field_name], 25) - distance].index, inplace=True)\n",
    "\n",
    "# drop_outliers(df_cleaned, 'LotArea')    \n",
    "df_cleaned_no_outlier = df.copy()\n",
    "for feature in X_numerical_not_missing_values_labels:\n",
    "    drop_outliers(df_cleaned_no_outlier, feature)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"nb of rows with outliers:{}, without: {}\".format(df.shape[0],df_cleaned_no_outlier.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are currently removing far too many items, to review later.\n",
    "can be done with sklearn anyway http://scikit-learn.org/stable/modules/outlier_detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature_columns=filter(lambda x: x !=\"SalePrice\" and x!=\"Id\", df.columns)\n",
    "# feature_numerical_columns = df[feature_columns].select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_numerical_columns=X_numerical_not_missing_values_labels\n",
    "prediction_column=\"SalePrice\"\n",
    "# # print(feature_columns)\n",
    "X = df[feature_numerical_columns]\n",
    "Y=df[[prediction_column]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier();\n",
    "model = model.fit(X, Y)    \n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"label {} : {}\".format(feature_numerical_columns[f],importances[indices[f]]))\n",
    "# print(indices)\n",
    "\n",
    "# plt.bar(range(X.shape[1]),importances[indices],align='center')\n",
    "# plt.xticks(range(X.shape[1]),feature_numerical_columns,rotation=90);\n",
    "# plt.rcParams[\"figure.figsize\"] = (17,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To draw graph and select features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot Check Algorithms\n",
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[X_numerical_not_missing_values_labels]\n",
    "Y=df[[\"SalePrice\"]];\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.33,random_state=42)\n",
    "print(Y_train.head())\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#training\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn import preprocessing\n",
    "\n",
    "models = []\n",
    "models.append((\"SVC\",SVC()))\n",
    "models.append((\"LinearSVC\",LinearSVC()))\n",
    "models.append((\"KNeighbors\",KNeighborsClassifier()))\n",
    "models.append((\"DecisionTree\",DecisionTreeClassifier()))\n",
    "models.append((\"RandomForest\",RandomForestClassifier()))\n",
    "\n",
    "modelsWhichNeedNormalization = []\n",
    "modelsWhichNeedNormalization.append((\"LogisticRegression\",LogisticRegression()))\n",
    "modelsWhichNeedNormalization.append((\"MLPClassifier\",MLPClassifier(solver='lbfgs', random_state=0)))\n",
    "modelsWhichNeedNormalization.append((\"LinearRegression\", LinearRegression()))\n",
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"5 expected values: {}\\n\".format(Y_test[0:5].values))\n",
    "for name,model in models:\n",
    "#     Train the model using the training sets\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pre = model.predict(X_test)\n",
    "    print(\"Training on {}\\n   mean squared log error: {}\\n\".format(name,mean_squared_log_error(Y_test, y_pre)))\n",
    "    print(\"   5 predicted values: {}\".format(y_pre[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# for name,model in modelsWhichNeedNormalization:\n",
    "# #     Train the model using the training sets\n",
    "#     X_train_scaled = preprocessing.scale(X_train)\n",
    "#     model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "#     # Make predictions using the testing set\n",
    "#     X_test_scaled = preprocessing.scale(X_test)\n",
    "#     y_pre = model.predict(X_test_scaled)\n",
    "#     print(\"Training on {}: {}\".format(name,mean_squared_log_error(Y_test, y_pre)))\n",
    "\n",
    "# crash on Jeremie's laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
